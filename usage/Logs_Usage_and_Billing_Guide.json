{"data":{"type":"notebooks","attributes":{"name":"Logs Usage and Billing Guide","metadata":{"type":null},"time":{"live_span":"1mo"},"cells":[{"id":"kxb65rev","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"Hi Team! I've created this notebook to assist in reviewing Log Usage and Billing. Please let me know in our slack channel if the team has any questions. Thank you! "}}},{"id":"9zcqvfjf","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"**Disclaimer**: This notebook shows off some metrics in Datadog that can be used to estimate log usage. Information about pricing has been pulled from the [Log Pricing Docs](https://www.datadoghq.com/pricing/?product=log-management#log-management) and may not reflect the actual dollar values in your contract.\n\nYou can also review the [Log Management dashboard](https://app.datadoghq.com/dash/integration/30602/log-management---estimated-usage?from_ts=1676647005044&to_ts=1676650605044&live=true) to get further visibility into estimated usage."}}},{"id":"7g2o6gi5","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"## Ingested logs\n\n### Overview\n\nAll ingested logs get parsed through your [log pipelines](/logs/pipelines) ([docs](/logs/log_configuration/pipelines/?tab=source)). After logs are processed, all ingested logs are available in [Live Tail](https://app.datadoghq.com/logs/livetail) ([docs](/logs/explorer/live_tail)). After Live Tail, your logs have the option of being indexed, archived, converted to metrics, or any combination of those options.\n\n### Cost\n\nIngestion of logs is pretty cheap overall, so it's not as important to focus on them to reduce billing. Log ingested is priced by the quantity of bytes. Plans can vary, but one example is paying `$0.10`/`GB`.\n\n### How to control\n\nThe only way for Datadog not to ingest logs is to not send logs to Datadog in the first place. Either by not setting up the collection, or by using some kind of [exclusion config](https://docs.datadoghq.com/agent/logs/advanced_log_collection/?tab=configurationfile#filter-logs) at the agent or collector level. There is no way to control which logs are ingested from the Datadog UI.\n\nIt's usually not recommended to block logs before ingestion, because those logs won't be able to get rehydrated later, and it's often easier to just control which logs are indexed through the centralized Datadog UI."}}},{"id":"wcgetpvi","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"## Using `estimated_usage` metrics to estimate ingestion costs\n\n[Estimated Usage Metrics](https://docs.datadoghq.com/account_management/billing/usage_metrics/#overview) provide an estimate of how much Datadog expects your usage to cost. Since these numbers are actually calculated at the end of the month, in order to provide a live metric that can be graphed and alerted on the number can be `10-20%` different than what you actually end up being billed for.\n\nIn this scenario, we can take the metric representing the total count of ingested bytes for logs (`datadog.estimated_usage.logs.ingested_bytes`) and multiply that against our example price of `$0.10`/`GB`. Make sure to change this price to match what is in your contract."}}},{"id":"ydwwglao","type":"notebook_cells","attributes":{"definition":{"show_legend":true,"type":"timeseries","requests":[{"formulas":[{"alias":"$","formula":"query1 / 1000000000 * 0.1"}],"response_format":"timeseries","queries":[{"query":"avg:datadog.estimated_usage.logs.ingested_bytes{*} by {datadog_index}.rollup(sum, 86400)","data_source":"metrics","name":"query1"}],"style":{"palette":"cool","line_type":"solid","line_width":"normal"},"display_type":"bars"}],"yaxis":{"scale":"linear"}},"time":null,"split_by":{"keys":[],"tags":[]},"graph_size":"m"}},{"id":"tfzd7o0k","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"## Indexed logs\n\n### Overview\n\nIndexed logs are what most users interact with on a day to day basis. They are called indexed logs because they get stored in an [index](/logs/pipelines/indexes) that Datadog manages. All the logs on the [Log Search](/logs) and [Analytics](/logs?viz=timeseries) pages only displayed indexed logs. They are the same set of logs used for your dashboard and monitor queries.\n\nIndexed logs are available in your account for anywhere from 3-60 days with the default contracts. \n\n\n### Cost\n\nIndexed logs are the bulk of logging costs, so it's important to focus on them to reduce billing. Log indexing is priced by the quantity of log events. Plans can vary, but one example is paying `$1.70`/`1 million log events`.\n\n### How to control\n\nOf course, logs never ingested by Datadog can never be indexed, so it's possible to just never send logs to Datadog in the first place. But importantly **indexing is decoupling from ingestion**. Using exclusion filters on each index can allow you to control which logs are retained in Datadog's backend, and which are not. Logs that are excluded do not contribute towards your bill."}}},{"id":"w2xnslln","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"## Using `estimated_usage` metrics to estimate ingestion costs\n\nJust like before we can use an estimated metric to determine what our bill will look like at the end of the month. But instead of measure bytes ingested, this time we are measuring events indexed. So we'll take `datadog.estimated_usage.logs.ingested_events` but filter the metric to not include logs that weren't saved (`datadog_is_excluded:false`). Then we take that count of ingested logs and multiply it against the price in our contract.\n\n### Note about multiple indexes\n\nIf you have [multiple indexes](https://docs.datadoghq.com/logs/log_configuration/indexes/#multiple-indexes), the most likely reason is to have multiple retention periods. For example production logs will be kept for 1 week, production logs with a status of error will be kept for 1 month, and all lower environments like dev, staging, and qa will only be kept for 3 days. This will save on costs, but if you are trying to graph your estimated cost make sure to make a separate query for each index so that you can multiple the logs in that index by the correct price. The tag `datadog_index` is available for you to filter on."}}},{"id":"ddf9n3fb","type":"notebook_cells","attributes":{"definition":{"show_legend":true,"type":"timeseries","requests":[{"formulas":[{"alias":"$","formula":"query1 / 1000000 * 1.7"}],"response_format":"timeseries","queries":[{"query":"avg:datadog.estimated_usage.logs.ingested_events{datadog_is_excluded:false}.as_count().rollup(sum, 86400)","data_source":"metrics","name":"query1"}],"style":{"palette":"cool","line_type":"solid","line_width":"normal"},"display_type":"bars"}],"yaxis":{"scale":"linear"}},"time":null,"split_by":{"keys":[],"tags":[]},"graph_size":"m"}},{"id":"93uvcyrr","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"## Logging Without Limits\n\nThe process of choosing which ingested logs to include or [exclude from indexes](https://docs.datadoghq.com/logs/log_configuration/indexes/#exclusion-filters), which to [archive](https://docs.datadoghq.com/logs/log_configuration/archives), and which to [convert into custom metrics](https://docs.datadoghq.com/logs/log_configuration/logs_to_metrics) is called [Logging without Limits](https://www.datadoghq.com/blog/logging-without-limits/)\n\nThis [LWL guide in documentation](https://docs.datadoghq.com/logs/guide/getting-started-lwl/), walks through one method to figure out which logs to exclude."}}},{"id":"zi2wr5hz","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"## Indexed Log Breakdown\n\nThe visualizations below should allow your team to understand how the logs currently indexed within the trial are distributed across your various environments and services. This can serve as a reference area to develop an indexing and archiving strategy using the Logging Without Limits capabilities outlined above. The visualizations allow your team to interact with the categories as well as deep-dive the logs in the Log Explorer."}}},{"id":"0hv9xls2","type":"notebook_cells","attributes":{"definition":{"title":"Indexed Logs by Environment","requests":[{"formulas":[{"formula":"query1","limit":{"order":"desc"}}],"style":{"palette":"datadog16"},"response_format":"scalar","queries":[{"search":{"query":""},"data_source":"logs","compute":{"aggregation":"count"},"name":"query1","storage":"hot","indexes":["*"],"group_by":[{"facet":"env","sort":{"aggregation":"count","order":"desc"},"limit":10}]}]}],"type":"sunburst","legend":{"type":"automatic"}},"time":null}},{"id":"v3s4igm8","type":"notebook_cells","attributes":{"definition":{"title":"Indexed Logs by Service and Status","requests":[{"formulas":[{"formula":"query1","limit":{"order":"desc"}}],"style":{"palette":"datadog16"},"response_format":"scalar","queries":[{"search":{"query":""},"data_source":"logs","compute":{"aggregation":"count"},"name":"query1","storage":"hot","indexes":["*"],"group_by":[{"facet":"service","sort":{"aggregation":"count","order":"desc"},"limit":30},{"facet":"status","sort":{"aggregation":"count","order":"desc"},"limit":30}]}]}],"type":"sunburst","legend":{"type":"automatic"}},"time":null}},{"id":"du8aincc","type":"notebook_cells","attributes":{"definition":{"title":"Top Indexed Logs by Environment, Service, and Status","type":"query_table","requests":[{"response_format":"scalar","queries":[{"search":{"query":""},"data_source":"logs","compute":{"aggregation":"count"},"name":"query1","storage":"hot","indexes":["*"],"group_by":[{"facet":"env","sort":{"aggregation":"count","order":"desc"},"limit":10},{"facet":"service","sort":{"aggregation":"count","order":"desc"},"limit":10},{"facet":"status","sort":{"aggregation":"count","order":"desc"},"limit":10}]}],"formulas":[{"formula":"query1","limit":{"order":"desc"}}]}]},"time":null,"split_by":{"keys":[],"tags":[]},"graph_size":"m"}},{"id":"8ucf128p","type":"notebook_cells","attributes":{"definition":{"title":"Top Logs in Env N/A by Source and Service","requests":[{"formulas":[{"formula":"query1"}],"style":{"palette":"datadog16"},"response_format":"scalar","queries":[{"search":{"query":"-env:*"},"data_source":"logs","compute":{"aggregation":"count"},"name":"query1","storage":"hot","indexes":["*"],"group_by":[{"facet":"source","sort":{"aggregation":"count","order":"desc"},"limit":10},{"facet":"service","sort":{"aggregation":"count","order":"desc"},"limit":10}]}]}],"type":"sunburst"},"time":null,"graph_size":"m"}},{"id":"wq62e2wj","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"## How to Identify Unparsed Logs\n\nUnparsed logs can be found using the following search query. \n\n`datadog.pipelines:false`\n\nBelow are results of the unparsed logs grouped by Source and Service as well as a view of Top Patters found in the past day. The patterns view can assist your team in identifying log sources that may not be collecting multi-line logs appropriately."}}},{"id":"iqt5xjrd","type":"notebook_cells","attributes":{"definition":{"title":"Top Unparsed Logs by Source and Service","requests":[{"formulas":[{"formula":"query1","limit":{"order":"desc"}}],"style":{"palette":"datadog16"},"response_format":"scalar","queries":[{"search":{"query":"datadog.pipelines:false"},"data_source":"logs","compute":{"aggregation":"count"},"name":"query1","storage":"hot","indexes":["*"],"group_by":[{"facet":"source","sort":{"aggregation":"count","order":"desc"},"limit":10},{"facet":"service","sort":{"aggregation":"count","order":"desc"},"limit":10}]}]}],"type":"sunburst","legend":{"type":"automatic"}},"time":null}},{"id":"7ti7fyse","type":"notebook_cells","attributes":{"definition":{"title":"Top Patterns of Indexed Unparsed Logs past Day","requests":[{"query":{"query_string":"datadog.pipelines:false","data_source":"logs_pattern_stream","group_by":[{"facet":"source"},{"facet":"service"}],"indexes":[]},"response_format":"event_list","columns":[{"field":"status_line","width":"auto"},{"field":"matches","width":"auto"},{"field":"volume","width":"auto"},{"field":"source","width":"auto"},{"field":"service","width":"auto"},{"field":"message","width":"auto"}]}],"type":"list_stream"},"time":{"live_span":"1d"},"graph_size":"l"}},{"id":"zmv3hext","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"## Tips & Tricks\n\n### Multiline Logs\n\nSince logs are priced by the number of events, one common issue people encounter is with multiline logs that are not properly ingested. Imagine a Java stack trace like\n\n```java\n2018-01-03T09:24:24.983Z UTC Exception in thread \"main\" java.lang.NullPointerException\n        at com.example.myproject.Book.getTitle(Book.java:16)\n        at com.example.myproject.Author.getBookTitles(Author.java:25)\n        at com.example.myproject.Bootstrap.main(Bootstrap.java:14)\n```\n\nBecause the delimiter for logs is a new line character by default, each one of those logs will appear as its own log event. When in actuality, it should just be 1 single log event. Not only does this make the logs very difficult to process and search for, it increases the cost of this log from 1 log event to 4 log events. Most stack traces are much larger than this, and occur in large bursts when they do happen, so that can quickly contribute significantly to your bill.\n\nThis can be easily resolved through a [`multi_line` log processing rule](https://docs.datadoghq.com/agent/logs/advanced_log_collection/?tab=configurationfile#multi-line-aggregation) in your agent config. This cannot be fixed after the logs have been ingested."}}},{"id":"kl81dp2k","type":"notebook_cells","attributes":{"definition":{"type":"markdown","text":"### Excluding Containers\n\nIt's recommended to always send all logs to Datadog, but there are some exceptions. One of them is specific to containerized environments. By default all containers sys.out and sys.err streams are collected. However not all containers impact production systems directly, so those logs will probably never be used for investigations or postmortems.\n\nOne easy example of this is the Datadog Agent container. It's deployed once per node (Daemonset in Kubernetes), and the logs can be noisy and irrelevant to your team. So it's recommended to enable the [`DD_CONTAINER_EXCLUDE_LOGS` configuration](https://docs.datadoghq.com/containers/docker/?tab=standard#ignore-containers) to prevent the agent from collecting its own logs. That config can control "}}}],"template_variables":[]}}}